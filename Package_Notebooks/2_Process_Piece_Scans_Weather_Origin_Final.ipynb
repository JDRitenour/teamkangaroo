{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "214bcd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14842/4280649393.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dcdaed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/12 10:18:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import os\n",
    "\n",
    "# Set SPARK_LOCAL_IP to 127.0.0.1\n",
    "os.environ[\"SPARK_LOCAL_IP\"] = \"127.0.0.1\"\n",
    "\n",
    "# Initialize Spark session with a conservative memory allocation\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"USPS\") \\\n",
    "    .config(\"spark.executor.memory\", \"8G\") \\\n",
    "    .config(\"spark.driver.memory\", \"8G\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4G\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set the log level to ERROR to suppress WARN messages\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beb95350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/home/pk/DAEN690/package_data/PKG_Origin_PcLevel.txt\", header=True, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7b7b425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+\n",
      "|MailPieceID|ServiceTypeCode|StartTheClockZipCode|StopTheClockDate|ScheduledDeliveryDate|StopTheClockZipCode|MailClassCode|\n",
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+\n",
      "|88228305910|           001 |               37040|       1/16/2024|            1/16/2024|              15613|           G0|\n",
      "|88180422391|           001 |               37090|       1/16/2024|            1/16/2024|              92247|           G0|\n",
      "|88147885963|           055 |               37167|       1/11/2024|            1/11/2024|              33770|           PM|\n",
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c30a7192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 3:>                                                          (0 + 8) / 8]\r",
      "\r",
      "[Stage 3:====================================>                      (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|MailClassCode|\n",
      "+-------------+\n",
      "|           PM|\n",
      "|           BS|\n",
      "|           FC|\n",
      "|           EX|\n",
      "|             |\n",
      "|           SA|\n",
      "|           BL|\n",
      "|           IL|\n",
      "|           G0|\n",
      "|           LC|\n",
      "|           RP|\n",
      "|           CP|\n",
      "|           S2|\n",
      "|           IE|\n",
      "|           G1|\n",
      "|           BB|\n",
      "|           UP|\n",
      "|           DM|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('MailClassCode').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ff388c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115279"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "557633ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22794"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Local zipcodes to Nashville area ########\n",
    "zips = ['37013','37027','37072','37076','37115','37138','37201','37203','37204','37205',\n",
    "        '37206','37207','37208','37209','37210','37211','37212','37214','37215','37216',\n",
    "        '37217','37218','37219','37220','37221','37027','37064','37067','37069','37135',\n",
    "        '37014','37046','37062','37179','37174','37122','37121','37087','37090','37184',\n",
    "        '37138','37075','37075','37066','37148','37070','37072','37048','37188','37086',\n",
    "        '37167','37127','37218','37130']\n",
    "# Filter DataFrame where zip_code exists in the list\n",
    "df = df.filter(df.StartTheClockZipCode.isin(zips))\n",
    "df = df.filter(df.StopTheClockZipCode.isin(zips))\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2fc4325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MailPieceID: string (nullable = true)\n",
      " |-- ServiceTypeCode: string (nullable = true)\n",
      " |-- StartTheClockZipCode: string (nullable = true)\n",
      " |-- StopTheClockDate: string (nullable = true)\n",
      " |-- ScheduledDeliveryDate: string (nullable = true)\n",
      " |-- StopTheClockZipCode: string (nullable = true)\n",
      " |-- MailClassCode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04b6d6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+\n",
      "|MailPieceID|ServiceTypeCode|StartTheClockZipCode|StopTheClockDate|ScheduledDeliveryDate|StopTheClockZipCode|MailClassCode|\n",
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+\n",
      "|88341629744|           490 |               37217|      2024-01-18|           2024-01-19|              37216|           BS|\n",
      "|88387239947|           055 |               37211|      2024-01-20|           2024-01-20|              37216|           PM|\n",
      "|88203064922|           001 |               37206|      2024-01-11|           2024-01-12|              37201|           G0|\n",
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- MailPieceID: string (nullable = true)\n",
      " |-- ServiceTypeCode: string (nullable = true)\n",
      " |-- StartTheClockZipCode: string (nullable = true)\n",
      " |-- StopTheClockDate: date (nullable = true)\n",
      " |-- ScheduledDeliveryDate: date (nullable = true)\n",
      " |-- StopTheClockZipCode: string (nullable = true)\n",
      " |-- MailClassCode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "date_fields = [\"StopTheClockDate\",\"ScheduledDeliveryDate\"]\n",
    "\n",
    "for field in date_fields:\n",
    "    df = df.withColumn(field, to_date(df[field], \"M/d/yyyy\"))\n",
    "\n",
    "# Show the updated DataFrame\n",
    "df.show(3)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2af90fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 26:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|MailPieceID|count|\n",
      "+-----------+-----+\n",
      "+-----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col  # Import the col function\n",
    "\n",
    "duplicate_records_with_counts = df.groupBy(\"MailPieceID\") \\\n",
    "    .count() \\\n",
    "    .filter(col(\"count\") > 1)\n",
    "\n",
    "# Show if any duplicate records with their counts\n",
    "duplicate_records_with_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bac7e9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44476\n",
      "+-----------+-------------------+-------------------+------------------+--------------------+------------------+\n",
      "|MailPieceID|  min_scan_datetime|  max_scan_datetime|Distinct_zip_scans|Distinct_event_scans|time_delta_minutes|\n",
      "+-----------+-------------------+-------------------+------------------+--------------------+------------------+\n",
      "|88244076233|2024-01-14 05:24:39|2024-01-25 05:40:53|                 3|                   1|             15840|\n",
      "|88217514369|2024-01-14 04:27:22|2024-01-18 06:02:59|                 3|                   1|              5760|\n",
      "|88298654737|2024-01-19 06:37:56|2024-01-23 04:13:54|                 3|                   1|              5760|\n",
      "+-----------+-------------------+-------------------+------------------+--------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.read.parquet(\"/home/pk/DAEN690/Scans_processed.parquet\")\n",
    "print(df2.count())\n",
    "df2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8758fce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19131\n",
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+-------------------+-------------------+------------------+--------------------+------------------+\n",
      "|MailPieceID|ServiceTypeCode|StartTheClockZipCode|StopTheClockDate|ScheduledDeliveryDate|StopTheClockZipCode|MailClassCode|  min_scan_datetime|  max_scan_datetime|Distinct_zip_scans|Distinct_event_scans|time_delta_minutes|\n",
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+-------------------+-------------------+------------------+--------------------+------------------+\n",
      "|88341629744|           490 |               37217|      2024-01-18|           2024-01-19|              37216|           BS|2024-01-18 03:14:46|2024-01-18 03:14:46|                 1|                   1|                 0|\n",
      "|88387239947|           055 |               37211|      2024-01-20|           2024-01-20|              37216|           PM|2024-01-20 03:38:44|2024-01-20 03:38:44|                 1|                   1|                 0|\n",
      "|88363002022|           001 |               37179|      2024-01-22|           2024-01-20|              37138|           G0|2024-01-21 12:06:02|2024-01-21 12:06:02|                 1|                   1|                 0|\n",
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+-------------------+-------------------+------------------+--------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join the two DataFrames on MailPieceID\n",
    "joined_df = df.join(df2, \"MailPieceID\", \"inner\")\n",
    "print(joined_df.count())\n",
    "joined_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02069587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MailPieceID: string (nullable = true)\n",
      " |-- ServiceTypeCode: string (nullable = true)\n",
      " |-- StartTheClockZipCode: string (nullable = true)\n",
      " |-- StopTheClockDate: date (nullable = true)\n",
      " |-- ScheduledDeliveryDate: date (nullable = true)\n",
      " |-- StopTheClockZipCode: string (nullable = true)\n",
      " |-- MailClassCode: string (nullable = true)\n",
      " |-- min_scan_datetime: timestamp (nullable = true)\n",
      " |-- max_scan_datetime: timestamp (nullable = true)\n",
      " |-- Distinct_zip_scans: long (nullable = true)\n",
      " |-- Distinct_event_scans: long (nullable = true)\n",
      " |-- time_delta_minutes: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "403e36ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date\n",
    "\n",
    "joined_df = joined_df.withColumn(\"min_date\", to_date(col(\"min_scan_datetime\")))\n",
    "joined_df = joined_df.withColumn(\"max_date\", to_date(col(\"max_scan_datetime\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ef3a9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col, expr\n",
    "joined_df = joined_df.withColumn(\"late\", when(col(\"StopTheClockDate\") > col(\"ScheduledDeliveryDate\"), 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2f29686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+-------------------+-------------------+------------------+--------------------+------------------+----------+----------+----+\n",
      "|MailPieceID|ServiceTypeCode|StartTheClockZipCode|StopTheClockDate|ScheduledDeliveryDate|StopTheClockZipCode|MailClassCode|  min_scan_datetime|  max_scan_datetime|Distinct_zip_scans|Distinct_event_scans|time_delta_minutes|  min_date|  max_date|late|\n",
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+-------------------+-------------------+------------------+--------------------+------------------+----------+----------+----+\n",
      "|88341629744|           490 |               37217|      2024-01-18|           2024-01-19|              37216|           BS|2024-01-18 03:14:46|2024-01-18 03:14:46|                 1|                   1|                 0|2024-01-18|2024-01-18|   0|\n",
      "|88387239947|           055 |               37211|      2024-01-20|           2024-01-20|              37216|           PM|2024-01-20 03:38:44|2024-01-20 03:38:44|                 1|                   1|                 0|2024-01-20|2024-01-20|   0|\n",
      "|88363002022|           001 |               37179|      2024-01-22|           2024-01-20|              37138|           G0|2024-01-21 12:06:02|2024-01-21 12:06:02|                 1|                   1|                 0|2024-01-21|2024-01-21|   1|\n",
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+-------------------+-------------------+------------------+--------------------+------------------+----------+----------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c879cfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MailPieceID: string (nullable = true)\n",
      " |-- ServiceTypeCode: string (nullable = true)\n",
      " |-- StartTheClockZipCode: string (nullable = true)\n",
      " |-- StopTheClockDate: date (nullable = true)\n",
      " |-- ScheduledDeliveryDate: date (nullable = true)\n",
      " |-- StopTheClockZipCode: string (nullable = true)\n",
      " |-- MailClassCode: string (nullable = true)\n",
      " |-- min_scan_datetime: timestamp (nullable = true)\n",
      " |-- max_scan_datetime: timestamp (nullable = true)\n",
      " |-- Distinct_zip_scans: long (nullable = true)\n",
      " |-- Distinct_event_scans: long (nullable = true)\n",
      " |-- time_delta_minutes: integer (nullable = true)\n",
      " |-- min_date: date (nullable = true)\n",
      " |-- max_date: date (nullable = true)\n",
      " |-- late: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "068aaaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 54:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 54:===========================================>              (6 + 2) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "joined_df.write.mode('overwrite').parquet(\"/home/pk/DAEN690/PKG_Origin_Piece_Scans.parquet\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "160b0aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Combine Weathr Data ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2de158b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PKG_O = spark.read.parquet(\"/home/pk/DAEN690/PKG_Origin_Piece_Scans.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4aeed82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+-------------------+-------------------+------------------+--------------------+------------------+----------+----------+----+\n",
      "|MailPieceID|ServiceTypeCode|StartTheClockZipCode|StopTheClockDate|ScheduledDeliveryDate|StopTheClockZipCode|MailClassCode|  min_scan_datetime|  max_scan_datetime|Distinct_zip_scans|Distinct_event_scans|time_delta_minutes|  min_date|  max_date|late|\n",
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+-------------------+-------------------+------------------+--------------------+------------------+----------+----------+----+\n",
      "|88240074381|           001 |               37205|      2024-01-12|           2024-01-16|              37205|           G0|2024-01-12 05:22:55|2024-01-12 05:22:55|                 1|                   1|                 0|2024-01-12|2024-01-12|   0|\n",
      "|88363428326|           001 |               37221|      2024-01-19|           2024-01-22|              37221|           G0|2024-01-19 05:38:58|2024-01-19 05:38:58|                 1|                   1|                 0|2024-01-19|2024-01-19|   0|\n",
      "|88179404045|           70  |               37066|      2024-01-12|           2024-01-12|              37066|           FC|2024-01-11 06:27:22|2024-01-11 06:27:22|                 1|                   1|                 0|2024-01-11|2024-01-11|   0|\n",
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+-------------------+-------------------+------------------+--------------------+------------------+----------+----------+----+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- MailPieceID: string (nullable = true)\n",
      " |-- ServiceTypeCode: string (nullable = true)\n",
      " |-- StartTheClockZipCode: string (nullable = true)\n",
      " |-- StopTheClockDate: date (nullable = true)\n",
      " |-- ScheduledDeliveryDate: date (nullable = true)\n",
      " |-- StopTheClockZipCode: string (nullable = true)\n",
      " |-- MailClassCode: string (nullable = true)\n",
      " |-- min_scan_datetime: timestamp (nullable = true)\n",
      " |-- max_scan_datetime: timestamp (nullable = true)\n",
      " |-- Distinct_zip_scans: long (nullable = true)\n",
      " |-- Distinct_event_scans: long (nullable = true)\n",
      " |-- time_delta_minutes: integer (nullable = true)\n",
      " |-- min_date: date (nullable = true)\n",
      " |-- max_date: date (nullable = true)\n",
      " |-- late: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_PKG_O.show(3)\n",
    "df_PKG_O.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79681b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Date Ori: 2023-11-08\n",
      "Max Date Ori: 2024-05-11\n",
      "19131\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min, max\n",
    "min_date_Ori = df_PKG_O.agg(min(\"min_date\")).first()[0]\n",
    "max_date_Ori = df_PKG_O.agg(max(\"max_date\")).first()[0]\n",
    "\n",
    "# Show the minimum date\n",
    "print(\"Minimum Date Ori:\", min_date_Ori)\n",
    "print(\"Max Date Ori:\", max_date_Ori)\n",
    "print(df_PKG_O.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cb3e055",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Join Weather data to USPS data #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08984d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, col\n",
    "df_weather = spark.read.csv(\"weather_data.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "151fff23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Zip: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- TMIN: string (nullable = true)\n",
      " |-- TMAX: string (nullable = true)\n",
      " |-- PRCP: string (nullable = true)\n",
      " |-- SNOW: string (nullable = true)\n",
      "\n",
      "+-----+----------+----+----+----+----+\n",
      "|  Zip|      Date|TMIN|TMAX|PRCP|SNOW|\n",
      "+-----+----------+----+----+----+----+\n",
      "|37010|2024-01-11|None|None| 0.0| 0.0|\n",
      "|37010|2024-01-13|None|None|0.27|None|\n",
      "|37010|2024-01-21|None|None| 0.0| 0.0|\n",
      "+-----+----------+----+----+----+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_weather.printSchema()\n",
    "df_weather.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46469c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import FloatType, DateType\n",
    "\n",
    "df_weather = df_weather.withColumn(\"Date\", col(\"Date\").cast(DateType()))\n",
    "df_weather = df_weather.withColumn(\"TMIN\", col(\"TMIN\").cast(FloatType()))\n",
    "df_weather = df_weather.withColumn(\"TMAX\", col(\"TMAX\").cast(FloatType()))\n",
    "df_weather = df_weather.withColumn(\"PRCP\", col(\"PRCP\").cast(FloatType()))\n",
    "df_weather = df_weather.withColumn(\"SNOW\", col(\"SNOW\").cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "756d9cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Zip: string (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- TMIN: float (nullable = true)\n",
      " |-- TMAX: float (nullable = true)\n",
      " |-- PRCP: float (nullable = true)\n",
      " |-- SNOW: float (nullable = true)\n",
      "\n",
      "+-----+----------+----+----+----+----+\n",
      "|  Zip|      Date|TMIN|TMAX|PRCP|SNOW|\n",
      "+-----+----------+----+----+----+----+\n",
      "|37010|2024-01-11|NULL|NULL| 0.0| 0.0|\n",
      "|37010|2024-01-13|NULL|NULL|0.27|NULL|\n",
      "|37010|2024-01-21|NULL|NULL| 0.0| 0.0|\n",
      "+-----+----------+----+----+----+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_weather.printSchema()\n",
    "df_weather.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8749a226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MailPieceID: string (nullable = true)\n",
      " |-- ServiceTypeCode: string (nullable = true)\n",
      " |-- StartTheClockZipCode: string (nullable = true)\n",
      " |-- StopTheClockDate: date (nullable = true)\n",
      " |-- ScheduledDeliveryDate: date (nullable = true)\n",
      " |-- StopTheClockZipCode: string (nullable = true)\n",
      " |-- MailClassCode: string (nullable = true)\n",
      " |-- min_scan_datetime: timestamp (nullable = true)\n",
      " |-- max_scan_datetime: timestamp (nullable = true)\n",
      " |-- Distinct_zip_scans: long (nullable = true)\n",
      " |-- Distinct_event_scans: long (nullable = true)\n",
      " |-- time_delta_minutes: integer (nullable = true)\n",
      " |-- min_date: date (nullable = true)\n",
      " |-- max_date: date (nullable = true)\n",
      " |-- late: integer (nullable = true)\n",
      " |-- Zip_O: string (nullable = true)\n",
      " |-- Date_O: date (nullable = true)\n",
      " |-- TMIN_O: float (nullable = true)\n",
      " |-- TMAX_O: float (nullable = true)\n",
      " |-- PRCP_O: float (nullable = true)\n",
      " |-- SNOW_O: float (nullable = true)\n",
      "\n",
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+-------------------+-------------------+------------------+--------------------+------------------+----------+----------+----+-----+----------+------+------+------+------+\n",
      "|MailPieceID|ServiceTypeCode|StartTheClockZipCode|StopTheClockDate|ScheduledDeliveryDate|StopTheClockZipCode|MailClassCode|  min_scan_datetime|  max_scan_datetime|Distinct_zip_scans|Distinct_event_scans|time_delta_minutes|  min_date|  max_date|late|Zip_O|    Date_O|TMIN_O|TMAX_O|PRCP_O|SNOW_O|\n",
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+-------------------+-------------------+------------------+--------------------+------------------+----------+----------+----+-----+----------+------+------+------+------+\n",
      "|88240074381|           001 |               37205|      2024-01-12|           2024-01-16|              37205|           G0|2024-01-12 05:22:55|2024-01-12 05:22:55|                 1|                   1|                 0|2024-01-12|2024-01-12|   0|37205|2024-01-12|  NULL|  NULL|  0.02|  NULL|\n",
      "|88363428326|           001 |               37221|      2024-01-19|           2024-01-22|              37221|           G0|2024-01-19 05:38:58|2024-01-19 05:38:58|                 1|                   1|                 0|2024-01-19|2024-01-19|   0|37221|2024-01-19|   5.0|  28.0|   0.0|  NULL|\n",
      "|88179404045|           70  |               37066|      2024-01-12|           2024-01-12|              37066|           FC|2024-01-11 06:27:22|2024-01-11 06:27:22|                 1|                   1|                 0|2024-01-11|2024-01-11|   0|37066|2024-01-11|  NULL|  NULL|   0.0|   0.0|\n",
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+-------------------+-------------------+------------------+--------------------+------------------+----------+----------+----+-----+----------+------+------+------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16928"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform the join on Origin\n",
    "df_joined = df_PKG_O.join(df_weather, (df_PKG_O[\"StartTheClockZipCode\"] == df_weather[\"Zip\"]) & (df_PKG_O[\"min_date\"] == df_weather[\"Date\"]), how=\"inner\")\n",
    "\n",
    "# List of columns to rename\n",
    "columns_to_rename = ['Zip', 'Date', 'TMIN', 'TMAX', 'PRCP', 'SNOW']\n",
    "\n",
    "# New column names with '_O' suffix\n",
    "new_column_names = [f\"{col}_O\" for col in columns_to_rename]\n",
    "\n",
    "# Rename columns using withColumnRenamed in a loop\n",
    "for old_col, new_col in zip(columns_to_rename, new_column_names):\n",
    "    df_joined = df_joined.withColumnRenamed(old_col, new_col)\n",
    "\n",
    "df_joined.printSchema()\n",
    "df_joined.show(3)\n",
    "df_joined.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13795846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MailPieceID: string (nullable = true)\n",
      " |-- ServiceTypeCode: string (nullable = true)\n",
      " |-- StartTheClockZipCode: string (nullable = true)\n",
      " |-- StopTheClockDate: date (nullable = true)\n",
      " |-- ScheduledDeliveryDate: date (nullable = true)\n",
      " |-- StopTheClockZipCode: string (nullable = true)\n",
      " |-- MailClassCode: string (nullable = true)\n",
      " |-- min_scan_datetime: timestamp (nullable = true)\n",
      " |-- max_scan_datetime: timestamp (nullable = true)\n",
      " |-- Distinct_zip_scans: long (nullable = true)\n",
      " |-- Distinct_event_scans: long (nullable = true)\n",
      " |-- time_delta_minutes: integer (nullable = true)\n",
      " |-- min_date: date (nullable = true)\n",
      " |-- max_date: date (nullable = true)\n",
      " |-- late: integer (nullable = true)\n",
      " |-- Zip_O: string (nullable = true)\n",
      " |-- Date_O: date (nullable = true)\n",
      " |-- TMIN_O: float (nullable = true)\n",
      " |-- TMAX_O: float (nullable = true)\n",
      " |-- PRCP_O: float (nullable = true)\n",
      " |-- SNOW_O: float (nullable = true)\n",
      " |-- Zip_D: string (nullable = true)\n",
      " |-- Date_D: date (nullable = true)\n",
      " |-- TMIN_D: float (nullable = true)\n",
      " |-- TMAX_D: float (nullable = true)\n",
      " |-- PRCP_D: float (nullable = true)\n",
      " |-- SNOW_D: float (nullable = true)\n",
      "\n",
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+-------------------+-------------------+------------------+--------------------+------------------+----------+----------+----+-----+----------+------+------+------+------+-----+----------+------+------+------+------+\n",
      "|MailPieceID|ServiceTypeCode|StartTheClockZipCode|StopTheClockDate|ScheduledDeliveryDate|StopTheClockZipCode|MailClassCode|  min_scan_datetime|  max_scan_datetime|Distinct_zip_scans|Distinct_event_scans|time_delta_minutes|  min_date|  max_date|late|Zip_O|    Date_O|TMIN_O|TMAX_O|PRCP_O|SNOW_O|Zip_D|    Date_D|TMIN_D|TMAX_D|PRCP_D|SNOW_D|\n",
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+-------------------+-------------------+------------------+--------------------+------------------+----------+----------+----+-----+----------+------+------+------+------+-----+----------+------+------+------+------+\n",
      "|88240074381|           001 |               37205|      2024-01-12|           2024-01-16|              37205|           G0|2024-01-12 05:22:55|2024-01-12 05:22:55|                 1|                   1|                 0|2024-01-12|2024-01-12|   0|37205|2024-01-12|  NULL|  NULL|  0.02|  NULL|37205|2024-01-12|  NULL|  NULL|  0.02|  NULL|\n",
      "|88363428326|           001 |               37221|      2024-01-19|           2024-01-22|              37221|           G0|2024-01-19 05:38:58|2024-01-19 05:38:58|                 1|                   1|                 0|2024-01-19|2024-01-19|   0|37221|2024-01-19|   5.0|  28.0|   0.0|  NULL|37221|2024-01-19|   5.0|  28.0|   0.0|  NULL|\n",
      "|88179404045|           70  |               37066|      2024-01-12|           2024-01-12|              37066|           FC|2024-01-11 06:27:22|2024-01-11 06:27:22|                 1|                   1|                 0|2024-01-11|2024-01-11|   0|37066|2024-01-11|  NULL|  NULL|   0.0|   0.0|37066|2024-01-11|  NULL|  NULL|   0.0|   0.0|\n",
      "+-----------+---------------+--------------------+----------------+---------------------+-------------------+-------------+-------------------+-------------------+------------------+--------------------+------------------+----------+----------+----+-----+----------+------+------+------+------+-----+----------+------+------+------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17503"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform the join on Destination\n",
    "df_joined = df_joined.join(df_weather, (df_joined[\"StopTheClockZipCode\"] == df_weather[\"Zip\"]) & (df_joined[\"max_date\"] == df_weather[\"Date\"]), how=\"inner\")\n",
    "\n",
    "# List of columns to rename\n",
    "columns_to_rename = ['Zip', 'Date', 'TMIN', 'TMAX', 'PRCP', 'SNOW']\n",
    "\n",
    "# New column names with '_O' suffix\n",
    "new_column_names = [f\"{col}_D\" for col in columns_to_rename]\n",
    "\n",
    "# Rename columns using withColumnRenamed in a loop\n",
    "for old_col, new_col in zip(columns_to_rename, new_column_names):\n",
    "    df_joined = df_joined.withColumnRenamed(old_col, new_col)\n",
    "\n",
    "df_joined.printSchema()\n",
    "df_joined.show(3)\n",
    "df_joined.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc23ac5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark/python/pyspark/sql/pandas/types.py:563: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if not is_datetime64tz_dtype(pser.dtype):\n",
      "/opt/spark/python/pyspark/sql/pandas/types.py:379: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if is_datetime64tz_dtype(s.dtype):\n",
      "/opt/spark/python/pyspark/sql/pandas/types.py:563: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if not is_datetime64tz_dtype(pser.dtype):\n",
      "/opt/spark/python/pyspark/sql/pandas/types.py:379: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if is_datetime64tz_dtype(s.dtype):\n"
     ]
    }
   ],
   "source": [
    "# Convert Spark DataFrame to Pandas DataFrame\n",
    "df_original = df_joined.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64a998ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.drop(columns=['ScheduledDeliveryDate','MailPieceID','StopTheClockDate',\n",
    "                          'min_scan_datetime','max_scan_datetime','StartTheClockZipCode',\n",
    "                          'StopTheClockZipCode','Date_O','Date_D','min_date','max_date','Distinct_zip_scans'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2222132",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Local zipcodes to Nashville area ########\n",
    "zips = ['37013','37027','37072','37076','37115','37138','37201','37203','37204','37205',\n",
    "        '37206','37207','37208','37209','37210','37211','37212','37214','37215','37216',\n",
    "        '37217','37218','37219','37220','37221','37027','37064','37067','37069','37135',\n",
    "        '37014','37046','37062','37179','37174','37122','37121','37087','37090','37184',\n",
    "        '37138','37075','37075','37066','37148','37070','37072','37048','37188','37086',\n",
    "        '37167','37127','37218','37130']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "512ab6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df_original[df_original['Zip_D'].isin(zips)]\n",
    "df_original = df_original[df_original['Zip_O'].isin(zips)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0412a482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17503"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_original.index) #17503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5dd8afcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk/anaconda3/lib/python3.11/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "# df.to_csv(\"Package_ML.csv\", header=True)\n",
    "df_original.to_parquet('Package_ML.parquet.gzip', compression='gzip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca434bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982458a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
